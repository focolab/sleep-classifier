{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"tkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#import plottools as pt\n",
    "import remtools as rt\n",
    "import scoreblock as sb\n",
    "import eegplotter as ep\n",
    "\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dig_out_scores(s=None, trial=None, classifier='OVR', m='24h_8ch'):\n",
    "    \"\"\"quick hack to get a human and model scores for one trial\"\"\"\n",
    "\n",
    "    # WWRW scoreTag and scoreType columns, then the vector of scores\n",
    "    # scoreType (human, model, consensus, switch, etc)\n",
    "    # scoreTag (h-con, h-GS, m-OVR-24h_8ch, etc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # narrow down to trial\n",
    "    scbt = scb.keeprows(conditions=[('trial', trial)])\n",
    "\n",
    "    # human scores\n",
    "    df_keep = scbt.df[~scbt.df['scorer'].isna()].copy()\n",
    "    scb_hum = sb.ScoreBlock(df=df_keep, index_cols=scbt.copy_index_cols())\n",
    "\n",
    "    scoreType = ['human']*scb_hum.numrows\n",
    "    scoreTag = [ 'hum-%s' % (row['scorer']) for _, row in scb_hum.df.iterrows()]\n",
    "    scb_hum.df['scoreType'] = scoreType\n",
    "    scb_hum.df['scoreTag'] = scoreTag\n",
    "    scb_hum.index_cols += ['scoreType', 'scoreTag']\n",
    "\n",
    "    \n",
    "    # model scores\n",
    "    cc = [('classifier', classifier), ('M', m)]\n",
    "    scb_mdl = scbt.keeprows(conditions=cc, comparison='all')\n",
    "\n",
    "    scoreType = ['model']*scb_mdl.numrows\n",
    "    scoreTag = [ '%s-%s' % (row['classifier'], row['M']) for _, row in scb_mdl.df.iterrows()]\n",
    "    scb_mdl.df['scoreType'] = scoreType\n",
    "    scb_mdl.df['scoreTag'] = scoreTag\n",
    "    scb_mdl.index_cols += ['scoreType', 'scoreTag']\n",
    "\n",
    "\n",
    "\n",
    "    scb_out = scb_hum.stack(others=[scb_mdl])\n",
    "\n",
    "    return scb_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_pca = '../../sandbox/ANL-pca-A/pca-test.json'\n",
    "#f_pcaproj = '../../sandbox/ANL-pca-A/df_pca_prj.csv'\n",
    "f_features = '../../sandbox/ANL-preprocess-A-train/trial-374/staged-trial-data.json'\n",
    "f_scores = '../../sandbox/ANL-merged-scores-A/scoreblock-raw-merged.json'\n",
    "\n",
    "\n",
    "#f_features = '../../sandbox/ANL-preprocess-B-blind/trial-2391/staged-trial-data.json'\n",
    "#f_scores = '../../sandbox/ANL-merged-scores-B/scoreblock-raw-merged.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%autoreload 2\n",
    "\n",
    "#edf = rt.EDFData(f_edf)\n",
    "#pcaprj = pd.read_csv(f_pcaproj, index_col=0)\n",
    "std = rt.StagedTrialData.from_json(f_features)\n",
    "pca = rt.PCA.from_json(f_pca)\n",
    "scb = sb.ScoreBlock.from_json(f_scores)\n",
    "\n",
    "sbstack = dig_out_scores(s=scb, trial=std.trial, classifier='OVO', m='24h_8ch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "#matplotlib.rcdefaults()\n",
    "\n",
    "pp = ep.EEGPlotter(std=std, pca=pca, scores=sbstack)\n",
    "pp.render(viewEpoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
